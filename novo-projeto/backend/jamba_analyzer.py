"""
üß† Jamba AI 2.1 Integration - Project Structure Analyzer
Modelo h√≠brido SSM-Transformer da AI21 Labs com 256K tokens de contexto
Especializado em an√°lise e estrutura√ß√£o de projetos complexos

Autor: GitHub Copilot + Jamba AI 2.1
Data: 31/01/2026
"""

import os
import json
from typing import Dict, List, Optional
from datetime import datetime
import logging

# Type stubs for ai21 when not installed
class ChatMessage:
    def __init__(self, role: str, content: str):
        self.role = role
        self.content = content

class AI21Client:
    def __init__(self, api_key: str):
        pass

try:
    from ai21 import AI21Client as _AI21Client
    from ai21.models.chat import ChatMessage as _ChatMessage
    AI21Client = _AI21Client
    ChatMessage = _ChatMessage
except ImportError:
    logging.debug("ai21 package not installed, using stubs")

# =====================================================
# CONFIGURA√á√ÉO
# =====================================================

AI21_API_KEY = os.getenv("AI21_API_KEY", "")
JAMBA_MODEL = "ai21/jamba-large-1.7"  # OpenRouter format

# =====================================================
# CLIENTE JAMBA
# =====================================================

class JambaStructureAnalyzer:
    """
    Analisador de estrutura de projeto usando Jamba AI 2.1
    
    Capacidades:
    - An√°lise de arquitetura completa (at√© 256K tokens)
    - Refatora√ß√£o e sugest√µes de estrutura
    - Detec√ß√£o de padr√µes e anti-patterns
    - Gera√ß√£o de documenta√ß√£o autom√°tica
    - Code review contextual
    """
    
    def __init__(self):
        if not AI21_API_KEY:
            raise ValueError("AI21_API_KEY √© obrigat√≥ria. Configure a vari√°vel de ambiente.")
        self.client = AI21Client(api_key=AI21_API_KEY)
        
        self.model = JAMBA_MODEL
        self.max_tokens = 4096
        self.temperature = 0.3  # Baixa para respostas mais determin√≠sticas
    
    def analyze_project_structure(
        self,
        project_files: List[Dict[str, str]],
        analysis_type: str = "architecture"
    ) -> Dict:
        """
        Analisa estrutura completa do projeto
        
        Args:
            project_files: Lista de arquivos [{path: str, content: str}]
            analysis_type: Tipo de an√°lise
                - "architecture": Vis√£o geral da arquitetura
                - "refactor": Sugest√µes de refatora√ß√£o
                - "security": An√°lise de seguran√ßa
                - "performance": Otimiza√ß√µes de performance
                - "documentation": Gera√ß√£o de docs
        
        Returns:
            Dict com an√°lise completa e recomenda√ß√µes
        """
        
        # Construir contexto do projeto
        project_context = self._build_project_context(project_files)
        
        # Prompt espec√≠fico por tipo
        system_prompt = self._get_system_prompt(analysis_type)
        
        try:
            messages = [
                ChatMessage(
                    role="system",
                    content=system_prompt
                ),
                ChatMessage(
                    role="user",
                    content=f"""Analise este projeto:

{project_context}

Forne√ßa uma an√°lise detalhada focada em: {analysis_type}"""
                )
            ]
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            return {
                "success": True,
                "analysis": response.choices[0].message.content,
                "model": self.model,
                "tokens_used": response.usage.total_tokens,
                "analysis_type": analysis_type,
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logging.error(f"Jamba analysis error: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": "Erro ao analisar projeto com Jamba."
            }
    
    def suggest_refactoring(
        self,
        component_code: str,
        component_type: str = "component"
    ) -> Dict:
        """
        Sugere refatora√ß√£o para um componente espec√≠fico
        
        Args:
            component_code: C√≥digo do componente
            component_type: Tipo (component, service, model, etc)
        
        Returns:
            Dict com sugest√µes de refatora√ß√£o
        """
        
        prompt = f"""Como especialista em Clean Code e arquitetura, analise este {component_type}:

```
{component_code}
```

Forne√ßa:
1. **An√°lise de Qualidade**: Problemas identificados
2. **Refatora√ß√£o**: C√≥digo refatorado seguindo best practices
3. **Explica√ß√£o**: O que foi melhorado e por qu√™
4. **Testes**: Sugest√£o de testes unit√°rios
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    ChatMessage(role="user", content=prompt)
                ],
                max_tokens=self.max_tokens,
                temperature=0.3
            )
            
            return {
                "success": True,
                "refactoring": response.choices[0].message.content,
                "original_lines": len(component_code.splitlines()),
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def generate_architecture_diagram(
        self,
        project_structure: Dict
    ) -> Dict:
        """
        Gera diagrama de arquitetura em formato Mermaid
        
        Args:
            project_structure: Estrutura do projeto
        
        Returns:
            Dict com c√≥digo Mermaid do diagrama
        """
        
        prompt = f"""Com base nesta estrutura de projeto, gere um diagrama Mermaid completo:

{json.dumps(project_structure, indent=2)}

O diagrama deve incluir:
- Arquitetura de alto n√≠vel (C4 Model - Context)
- Componentes principais
- Fluxo de dados
- Integra√ß√µes externas

Retorne APENAS o c√≥digo Mermaid v√°lido, sem explica√ß√µes."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    ChatMessage(role="user", content=prompt)
                ],
                max_tokens=2048,
                temperature=0.2
            )
            
            mermaid_code = response.choices[0].message.content
            
            # Extrair apenas c√≥digo Mermaid
            if "```mermaid" in mermaid_code:
                mermaid_code = mermaid_code.split("```mermaid")[1].split("```")[0].strip()
            
            return {
                "success": True,
                "diagram": mermaid_code,
                "format": "mermaid",
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def code_review(
        self,
        diff: str,
        context: Optional[str] = None
    ) -> Dict:
        """
        Code review automatizado de mudan√ßas
        
        Args:
            diff: Git diff das mudan√ßas
            context: Contexto adicional do PR
        
        Returns:
            Dict com review detalhado
        """
        
        prompt = f"""Como reviewer experiente, analise estas mudan√ßas:

```diff
{diff}
```

{f'Contexto: {context}' if context else ''}

Forne√ßa:
1. **Aprova√ß√£o**: ‚úÖ Aprovar | ‚ö†Ô∏è Aprovar com ressalvas | ‚ùå Rejeitar
2. **Problemas Cr√≠ticos**: Issues que impedem merge
3. **Sugest√µes**: Melhorias opcionais
4. **Seguran√ßa**: Vulnerabilidades detectadas
5. **Testes**: Cobertura necess√°ria
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    ChatMessage(role="user", content=prompt)
                ],
                max_tokens=3072,
                temperature=0.3
            )
            
            return {
                "success": True,
                "review": response.choices[0].message.content,
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    # =====================================================
    # HELPERS PRIVADOS
    # =====================================================
    
    def _build_project_context(self, files: List[Dict]) -> str:
        """Constr√≥i contexto formatado do projeto"""
        context_parts = []
        
        for file in files[:50]:  # Limitar a 50 arquivos principais
            path = file.get("path", "unknown")
            content = file.get("content", "")
            
            # Truncar arquivos muito grandes
            if len(content) > 5000:
                content = content[:5000] + "\n... (truncado)"
            
            context_parts.append(f"""
## {path}
```
{content}
```
""")
        
        return "\n".join(context_parts)
    
    def _get_system_prompt(self, analysis_type: str) -> str:
        """Retorna system prompt espec√≠fico por tipo de an√°lise"""
        
        prompts = {
            "architecture": """Voc√™ √© um arquiteto de software s√™nior especializado em:
- Clean Architecture
- Microservices
- Domain-Driven Design
- Design Patterns
- SOLID principles

Analise a arquitetura do projeto e forne√ßa insights profundos sobre estrutura, padr√µes e oportunidades de melhoria.""",
            
            "refactor": """Voc√™ √© um especialista em refatora√ß√£o e Clean Code.
Identifique code smells, duplica√ß√µes, complexidade excessiva e sugira refatora√ß√µes concretas.""",
            
            "security": """Voc√™ √© um especialista em seguran√ßa de aplica√ß√µes.
Identifique vulnerabilidades, exposi√ß√µes de dados sens√≠veis, falhas de autentica√ß√£o/autoriza√ß√£o.""",
            
            "performance": """Voc√™ √© um especialista em otimiza√ß√£o de performance.
Identifique gargalos, consultas N+1, algoritmos ineficientes, problemas de mem√≥ria.""",
            
            "documentation": """Voc√™ √© um technical writer especializado em documenta√ß√£o de c√≥digo.
Gere documenta√ß√£o clara, concisa e completa seguindo melhores pr√°ticas."""
        }
        
        return prompts.get(analysis_type, prompts["architecture"])
    
    def _mock_analysis(self, files: List[Dict], analysis_type: str) -> Dict:
        """An√°lise mock quando Jamba n√£o est√° dispon√≠vel"""
        return {
            "success": True,
            "analysis": f"""## An√°lise Mock ({analysis_type})

‚ö†Ô∏è **AI21 API Key n√£o configurada**

Para habilitar an√°lise com Jamba AI 2.1:
1. Obtenha API key em: https://studio.ai21.com/
2. Configure: AI21_API_KEY no Azure Functions
3. Reinicie a aplica√ß√£o

**Arquivos analisados**: {len(files)}
**Modelo**: Jamba 1.5 Large (256K context)
""",
            "model": "mock",
            "analysis_type": analysis_type,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    def _mock_refactoring(self, code: str, component_type: str) -> Dict:
        """Refatora√ß√£o mock"""
        return {
            "success": True,
            "refactoring": f"""## Refatora√ß√£o Mock

Configure AI21_API_KEY para an√°lise real com Jamba.

**Tipo**: {component_type}
**Linhas**: {len(code.splitlines())}
""",
            "timestamp": datetime.utcnow().isoformat()
        }


# =====================================================
# DUAL-MODEL STRATEGY
# =====================================================

class HybridAIService:
    """
    Servi√ßo h√≠brido usando Phi-Silica (chat) + Jamba (estrutura√ß√£o)
    
    - Phi-Silica 3.6: Chat contextual, perguntas r√°pidas
    - Jamba AI 2.1: An√°lise profunda, refatora√ß√£o, arquitetura
    """
    
    def __init__(self):
        self.jamba = JambaStructureAnalyzer()
        # Phi-Silica j√° existe em ai_assistant.py
    
    def analyze_and_chat(self, query: str, project_files: List[Dict] = None) -> Dict:
        """
        Decide qual modelo usar baseado no query
        
        Jamba para:
        - "analise a arquitetura"
        - "refatore este c√≥digo"
        - "revise este PR"
        - "gere documenta√ß√£o"
        
        Phi-Silica para:
        - "como cadastrar?"
        - "o que √© CAR?"
        - Chat r√°pido
        """
        
        query_lower = query.lower()
        
        # Keywords que ativam Jamba
        jamba_keywords = [
            "arquitetura", "estrutura", "refator", "review", 
            "analis", "otimiz", "melhori", "diagram", "documenta√ß"
        ]
        
        use_jamba = any(keyword in query_lower for keyword in jamba_keywords)
        
        if use_jamba and project_files:
            return {
                "model": "jamba-ai-2.1",
                "response": self.jamba.analyze_project_structure(project_files)
            }
        else:
            return {
                "model": "phi-silica-3.6",
                "response": "Use ai_assistant.py para chat contextual"
            }


# =====================================================
# EXEMPLO DE USO
# =====================================================

if __name__ == "__main__":
    analyzer = JambaStructureAnalyzer()
    
    # Exemplo: Analisar arquitetura
    files = [
        {"path": "backend/models.py", "content": "# c√≥digo..."},
        {"path": "frontend/App.tsx", "content": "// c√≥digo..."}
    ]
    
    result = analyzer.analyze_project_structure(files, "architecture")
    print(json.dumps(result, indent=2))
